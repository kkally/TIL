
117
```
118
​
119
• validation을 설정하여 훈련 데이터로 검증한다. 이때 validation은 train data가 아닌 데이터를 사용해야 한다. 여기서는 train data에서 일부만 분리해서 사용했다. 이때 model.fit() 메서드는 History 객체를 반환한다. history 객체는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리인 history 속성을 갖는다.
120
​
121
​
122
​
123
```python
124
import matplotlib.pyplot as plt
125
​
126
history_dict = history.history
127
loss = history_dict['loss']
128
val_loss = history_dict['val_loss']
129
​
130
epochs = range(1, len(loss)+1)
131
​
132
plt.figure(figsize=(16,12))
133
plt.plot(epochs, loss, 'bo', label='Training loss')
134
plt.plot(epochs, val_loss, 'b', label = 'Validation loss')
135
plt.xlabel('Epochs')
136
plt.ylabel('loss')
137
plt.legend()
138
plt.show()
139
​
140
​
141
plt.clf()
142
acc = history_dict['acc']
143
val_acc = history_dict['val_acc']
144
​
145
plt.figure(figsize=(16,12))
146
plt.plot(epochs, acc, 'bo', label = 'Training acc')
147
plt.plot(epochs, val_acc, 'b', label='Validation acc')
148
plt.title('Training and validation accuracy')
149
plt.xlabel('Epochs')
150
plt.ylabel('Accuracy')
151
plt.legend()
152
plt.show()
153
```
154
​
155
• 그래프를 통해 loss와 acc를 확인한다. 그냥 train data의 검증은 성능이 계속 향상되지만, 실제 validation을 확인하면 그렇지 않은 것을 확인할 수 있다.
156
​
157
• validation을 통해 과적합이 시작된 부분을 확인한다.
158
​
159
​
160
​
161
---
162
​
163
​
164
​
165
### 새로운 모델 훈련
166
​
167
```python
168
model = models.Sequential()
169
model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))
170
model.add(layers.Dense(16, activation='relu'))
171
model.add(layers.Dense(1, activation='sigmoid'))
172
​
173
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
174
model.fit(x_train, y_train, epochs=5, batch_size=512)
175
results = model.evaluate(x_test, y_test)
176
print(results)
177
```
178
​
179
• 과적합이 시작된 부분을 찾은 뒤, 새로운 모델을 만들어 최적의 모델을 훈련시킨다. 새로 모델을 만드는 이유는 이미 훈련된 데이터에서 다시 훈련시키면 무용지물이 되기 때문이다.
